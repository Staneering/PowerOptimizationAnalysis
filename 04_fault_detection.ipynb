{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a101fcc6",
   "metadata": {},
   "source": [
    "# Fault Detection\n",
    "\n",
    "    ## Fault Detection\n",
    "    In this notebook, we implement anomaly detection using Isolation Forest and Autoencoders.\n",
    "    \n",
    "    Steps:\n",
    "    1. Implement Isolation Forest for detecting faults.\n",
    "    2. Train Autoencoders for anomaly detection.\n",
    "    3. Visualize anomalies in voltage and power consumption data.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed9998-b1c1-4672-9147-83bb3c6c39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes, let's move on to the **fourth notebook**: **Fault Detection**.\n",
    "\n",
    "In this notebook, we'll focus on **anomaly detection** using two techniques:\n",
    "\n",
    "1. **Isolation Forest** (for outlier detection).\n",
    "2. **Autoencoders** (for anomaly detection based on reconstruction error).\n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Detect faults** in the dataset (e.g., voltage spikes, sudden power surges).\n",
    "2. **Label anomalies** based on the **Isolation Forest** and **Autoencoders** results.\n",
    "3. **Evaluate the detection performance** using the **same metrics** (accuracy, precision, recall, and F1 score) as before.\n",
    "\n",
    "---\n",
    "\n",
    "### **Fourth Notebook: `04_fault_detection.ipynb`**\n",
    "\n",
    "#### **Markdown Cell**:\n",
    "\n",
    "```markdown\n",
    "# Fault Detection\n",
    "\n",
    "In this notebook, we implement anomaly detection using **Isolation Forest** and **Autoencoders**.\n",
    "\n",
    "Steps:\n",
    "1. Use **Isolation Forest** to detect faults in power distribution.\n",
    "2. Train **Autoencoders** for anomaly detection.\n",
    "3. Label anomalies (potential faults) based on the reconstruction error.\n",
    "4. Evaluate the performance of fault detection using metrics like accuracy, precision, recall, and F1 score.\n",
    "```\n",
    "\n",
    "#### **Code Cell**:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries for anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv('preprocessed_power_consumption.csv', index_col='Timestamp')\n",
    "\n",
    "# Select relevant features for anomaly detection\n",
    "features = ['Voltage', 'Global_active_power', 'Global_intensity']\n",
    "X = df[features]\n",
    "\n",
    "# **1. Isolation Forest for Fault Detection**\n",
    "# Initialize Isolation Forest model\n",
    "model_iforest = IsolationForest(n_estimators=200, contamination=0.05, max_samples=0.9, random_state=42)\n",
    "model_iforest.fit(X)  # Train the model on the selected features\n",
    "\n",
    "# Predict anomalies using Isolation Forest\n",
    "df['anomaly_iforest'] = model_iforest.predict(X)  # -1 for anomaly, 1 for normal\n",
    "df['anomaly_iforest'] = df['anomaly_iforest'].map({1: 'Normal', -1: 'Anomaly'})  # Map the predictions\n",
    "\n",
    "# **2. Autoencoders for Anomaly Detection**\n",
    "# Normalize the data before passing to Autoencoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define Autoencoder model structure\n",
    "input_layer = Input(shape=(X_scaled.shape[1],))\n",
    "encoded = Dense(128, activation='relu')(input_layer)  # Encoder layer\n",
    "decoded = Dense(X_scaled.shape[1], activation='sigmoid')(encoded)  # Decoder layer (reconstruction)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train Autoencoder model\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_scaled, X_scaled))\n",
    "\n",
    "# **Anomaly detection with Autoencoders**\n",
    "reconstructed = autoencoder.predict(X_scaled)  # Reconstructed data from Autoencoder\n",
    "reconstruction_error = np.mean(np.abs(reconstructed - X_scaled), axis=1)  # Reconstruction error\n",
    "\n",
    "# Set threshold for anomaly detection (top 5% reconstruction errors)\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "df['anomaly_autoencoder'] = (reconstruction_error > threshold).astype(int)  # 1 for anomaly, 0 for normal\n",
    "\n",
    "# **3. Evaluate the Performance**\n",
    "# Assuming we have labels or a threshold for detecting faults, we can evaluate performance.\n",
    "# For demonstration, assume anomalies detected by both methods are potential faults.\n",
    "\n",
    "# Displaying first few rows with anomalies labeled\n",
    "print(\"\\nFirst few rows with anomaly labels:\")\n",
    "print(df[['Voltage', 'Global_active_power', 'anomaly_iforest', 'anomaly_autoencoder']].head(10))\n",
    "\n",
    "# **4. Evaluate Model Performance using Precision, Recall, F1 Score**\n",
    "# Here, we assume that anomalies labeled by 'anomaly_iforest' or 'anomaly_autoencoder' are the faults.\n",
    "y_true = (df['anomaly_iforest'] == 'Anomaly').astype(int)  # True labels for faults\n",
    "y_pred_iforest = (df['anomaly_iforest'] == 'Anomaly').astype(int)  # Predicted anomalies by Isolation Forest\n",
    "y_pred_autoencoder = df['anomaly_autoencoder']  # Predicted anomalies by Autoencoder\n",
    "\n",
    "# Evaluation for Isolation Forest\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"\\nIsolation Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred_iforest):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_iforest):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_iforest):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_true, y_pred_iforest):.4f}\")\n",
    "print(\"\\nClassification Report for Isolation Forest:\\n\", classification_report(y_true, y_pred_iforest))\n",
    "\n",
    "# Evaluation for Autoencoder\n",
    "print(\"\\nAutoencoder Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_autoencoder):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_true, y_pred_autoencoder):.4f}\")\n",
    "print(\"\\nClassification Report for Autoencoder:\\n\", classification_report(y_true, y_pred_autoencoder))\n",
    "\n",
    "# **Visualize Anomalies**\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(df.index, df['Voltage'], c=df['anomaly_iforest'].map({'Normal': 'blue', 'Anomaly': 'red'}), label='Anomalies')\n",
    "plt.title('Anomalies in Voltage (Isolation Forest)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(df.index, df['Voltage'], c=df['anomaly_autoencoder'].map({0: 'blue', 1: 'red'}), label='Anomalies')\n",
    "plt.title('Anomalies in Voltage (Autoencoder)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of the Script**:\n",
    "\n",
    "1. **Isolation Forest**:\n",
    "\n",
    "   * We use **Isolation Forest** to detect anomalies based on **features** such as **Voltage**, **Global\\_active\\_power**, and **Global\\_intensity**. The model is trained and anomalies are detected.\n",
    "   * Anomalies are labeled as **'Anomaly'** and **'Normal'**.\n",
    "\n",
    "2. **Autoencoders**:\n",
    "\n",
    "   * We use **Autoencoders** to detect anomalies by training the model on the scaled dataset and then comparing the **reconstruction error** to identify anomalies.\n",
    "   * The **top 5%** of reconstruction errors are classified as anomalies.\n",
    "\n",
    "3. **Model Evaluation**:\n",
    "\n",
    "   * We use **accuracy**, **precision**, **recall**, and **F1 score** to evaluate the performance of both the **Isolation Forest** and **Autoencoder** models.\n",
    "   * We assume the **'Anomaly'** labels from both models represent **faults**.\n",
    "\n",
    "4. **Visualization**:\n",
    "\n",
    "   * The anomalies detected by **Isolation Forest** and **Autoencoder** are visualized on the **Voltage** time series. Red points represent anomalies, while blue represents normal data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**:\n",
    "\n",
    "1. **Run the Fault Detection** notebook to detect anomalies (faults) using both **Isolation Forest** and **Autoencoders**.\n",
    "2. **Evaluate** the performance using metrics like **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "3. If you have **real fault data**, you can compare **predicted faults** with actual faults to assess the model's effectiveness.\n",
    "\n",
    "Let me know if you'd like to proceed with **running this notebook**, or if you'd like to dive into any other steps!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
