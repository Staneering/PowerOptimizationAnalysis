{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2526fd2b-1688-4b29-8b8d-c31dbd0e99f9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Week 5: Working with Cybersecurity Datasets**\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Introduction to Cybersecurity Datasets](#introduction-to-cybersecurity-datasets)\n",
    "2. [NSL-KDD Dataset](#nsl-kdd-dataset)\n",
    "3. [CICIDS Dataset](#cicids-dataset)\n",
    "4. [Real-World Datasets](#real-world-datasets)\n",
    "5. [Data Preprocessing Techniques](#data-preprocessing-techniques)\n",
    "6. [Hands-on: Feature Extraction for Security Analysis](#hands-on-feature-extraction-for-security-analysis)\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Introduction to Cybersecurity Datasets**\n",
    "\n",
    "Data science and machine learning in **cybersecurity** heavily rely on datasets that contain network traffic, user behaviors, and security logs. These datasets allow researchers and professionals to detect threats, identify anomalies, and build Intrusion Detection Systems (IDS).\n",
    "\n",
    "In this class, we will work with three commonly used cybersecurity datasets:\n",
    "\n",
    "* **NSL-KDD Dataset**\n",
    "* **CICIDS Dataset**\n",
    "* **Real-world cybersecurity datasets**\n",
    "\n",
    "We'll also apply **data preprocessing techniques** to prepare the data for **feature extraction** and **analysis**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. NSL-KDD Dataset**\n",
    "\n",
    "The **NSL-KDD** dataset is an improved version of the **KDD Cup 1999** dataset. It is widely used for training machine learning models to detect network intrusions. It contains network traffic features like **protocol**, **duration**, **service**, and **label** (normal or attack).\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "* **Duration**: Connection duration in seconds.\n",
    "* **Protocol Type**: The protocol used (e.g., TCP, UDP, ICMP).\n",
    "* **Service**: The service or application involved (e.g., HTTP, FTP).\n",
    "* **Label**: The classification label (normal or one of many attack types like **DoS**, **Probe**, **U2R**, **R2L**).\n",
    "\n",
    "### Loading the NSL-KDD Dataset\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the NSL-KDD dataset\n",
    "df_nsl = pd.read_csv('KDDTrain+.csv', header=None)\n",
    "\n",
    "# Assign column names\n",
    "df_nsl.columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', \n",
    "                  'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'num_compromised', \n",
    "                  'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', \n",
    "                  'num_access_files', 'num_outbound_cmds', 'is_hot_login', 'is_guest_login', \n",
    "                  'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', \n",
    "                  'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n",
    "                  'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', \n",
    "                  'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "                  'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', \n",
    "                  'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']\n",
    "\n",
    "# Check the first few rows\n",
    "df_nsl.head()\n",
    "```\n",
    "\n",
    "### Example: Analyzing the NSL-KDD Dataset\n",
    "\n",
    "We can preprocess this dataset by encoding categorical features such as **protocol\\_type**, **service**, and **flag**.\n",
    "\n",
    "```python\n",
    "# One-hot encoding for categorical variables\n",
    "df_nsl = pd.get_dummies(df_nsl, columns=['protocol_type', 'service', 'flag'])\n",
    "\n",
    "# Check the first few rows after encoding\n",
    "df_nsl.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. CICIDS Dataset**\n",
    "\n",
    "The **CICIDS** (Canadian Institute for Cybersecurity Intrusion Detection System) dataset is another widely used dataset for cybersecurity research. It includes labeled network traffic data and contains **benign** as well as **malicious traffic**.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "* **Features similar to NSL-KDD** (bytes transferred, number of connections, etc.).\n",
    "* Attack categories such as **DDoS**, **Botnet**, **Brute Force**, and **Port Scanning**.\n",
    "* The dataset provides realistic network traffic, including modern cyber threats.\n",
    "\n",
    "### Loading the CICIDS Dataset\n",
    "\n",
    "```python\n",
    "# Example of loading CICIDS dataset\n",
    "df_cicids = pd.read_csv('cicids_2021.csv')\n",
    "\n",
    "# Check the first few rows\n",
    "df_cicids.head()\n",
    "```\n",
    "\n",
    "### Preprocessing the CICIDS Dataset\n",
    "\n",
    "You can handle missing values, normalize numeric features, and apply **one-hot encoding** for categorical features, similar to the NSL-KDD dataset.\n",
    "\n",
    "```python\n",
    "# Handle missing values\n",
    "df_cicids.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_cicids[['src_bytes', 'dst_bytes', 'num_failed_logins']] = scaler.fit_transform(df_cicids[['src_bytes', 'dst_bytes', 'num_failed_logins']])\n",
    "\n",
    "# One-hot encoding\n",
    "df_cicids = pd.get_dummies(df_cicids, columns=['protocol_type', 'service'])\n",
    "\n",
    "# Check the first few rows after preprocessing\n",
    "df_cicids.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Real-world Datasets**\n",
    "\n",
    "In addition to **NSL-KDD** and **CICIDS**, real-world cybersecurity datasets, such as **network traffic logs** from enterprise systems or **publicly available datasets**, can be valuable for analyzing network behavior and detecting **anomalies**.\n",
    "\n",
    "### Example of Real-World Datasets:\n",
    "\n",
    "* **Flow-based Data**: Data representing network traffic, including bytes transferred and flow duration.\n",
    "* **System Logs**: Logs from firewalls, intrusion detection systems, or routers.\n",
    "* **Threat Intelligence Data**: Information on known cyber threats or attack patterns.\n",
    "\n",
    "These datasets can often be processed similarly to **NSL-KDD** or **CICIDS**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Data Preprocessing Techniques**\n",
    "\n",
    "Data preprocessing is an essential part of the data science workflow, especially in **cybersecurity**. It ensures that the data is clean, relevant, and ready for machine learning models.\n",
    "\n",
    "### Key Preprocessing Steps:\n",
    "\n",
    "1. **Handling Missing Values**:\n",
    "\n",
    "   * Use imputation (filling missing data with the mean, median, or mode) or remove rows with missing values.\n",
    "\n",
    "   ```python\n",
    "   df.fillna(df.mean(), inplace=True)  # Impute missing values with column mean\n",
    "   ```\n",
    "\n",
    "2. **Encoding Categorical Features**:\n",
    "\n",
    "   * Convert categorical features (e.g., `protocol_type`, `service`, `flag`) into numerical values using **one-hot encoding**.\n",
    "\n",
    "   ```python\n",
    "   df = pd.get_dummies(df, columns=['protocol_type', 'service', 'flag'])\n",
    "   ```\n",
    "\n",
    "3. **Scaling Features**:\n",
    "\n",
    "   * Normalize numerical features to have a consistent range using techniques like **Min-Max Scaling** or **Standardization**.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   scaler = StandardScaler()\n",
    "   df[['bytes', 'duration']] = scaler.fit_transform(df[['bytes', 'duration']])\n",
    "   ```\n",
    "\n",
    "4. **Feature Selection**:\n",
    "\n",
    "   * Select relevant features for the model, which could include metrics like **traffic duration**, **bytes transferred**, and **failed logins**.\n",
    "\n",
    "   ```python\n",
    "   features = df[['duration', 'src_bytes', 'dst_bytes', 'num_failed_logins']]\n",
    "   ```\n",
    "\n",
    "5. **Dealing with Imbalanced Data**:\n",
    "\n",
    "   * In cybersecurity datasets, the data is often **imbalanced** (e.g., many normal instances and few attack instances). Techniques like **oversampling**, **undersampling**, or using **SMOTE** (Synthetic Minority Over-sampling Technique) can be applied to balance the dataset.\n",
    "\n",
    "   ```python\n",
    "   from imblearn.over_sampling import SMOTE\n",
    "   smote = SMOTE(random_state=42)\n",
    "   X_res, y_res = smote.fit_resample(X, y)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Hands-on: Feature Extraction for Security Analysis**\n",
    "\n",
    "In this exercise, we will focus on **feature extraction** from the datasets to build a model that can classify network traffic as **normal** or **malicious**.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Load the dataset** and preprocess the data (handle missing values, scale numeric features, encode categorical features).\n",
    "2. **Select relevant features** for building the model.\n",
    "3. **Extract additional features** like **flow duration**, **source IP traffic** patterns, and **request types**.\n",
    "4. **Train a machine learning model** (e.g., Decision Tree, SVM, Neural Networks) on the dataset.\n",
    "5. **Evaluate the modelâ€™s performance** using metrics like **accuracy**, **precision**, **recall**, and **F1-score**.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Feature extraction: Select relevant features\n",
    "features = df[['duration', 'src_bytes', 'dst_bytes', 'num_failed_logins']]\n",
    "target = df['label']  # Target: normal or malicious traffic\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74de57-5967-418c-a9d0-d90fc9b5144b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
