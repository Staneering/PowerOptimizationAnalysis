{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6c5b02",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "    ## Model Evaluation\n",
    "    This notebook evaluates the classification models for voltage sag detection and fault detection using various performance metrics.\n",
    "    \n",
    "    Steps:\n",
    "    1. Evaluate Random Forest model for voltage sag detection.\n",
    "    2. Evaluate Isolation Forest and Autoencoders for fault detection.\n",
    "    3. Compare accuracy, precision, recall, and F1 score.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03ca5129-985f-4f92-a0cd-e2f514ff5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab0aaef-490e-4a8b-8e47-2941247d12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Global_active_power', 'Global_reactive_power', 'Voltage',\n",
       "       'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
       "       'Sub_metering_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284f8ae5-3b5d-4826-ac8a-05b865b3fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize voltage into discrete levels\n",
    "def categorize_voltage(voltage):\n",
    "    if voltage < 225:\n",
    "        return 'low_voltage'  # Category for low voltage\n",
    "    elif voltage <= 240:\n",
    "        return 'normal_voltage'  # Category for normal voltage\n",
    "    else:\n",
    "        return 'high_voltage'  # Category for high voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdd54fd-c237-42c9-9c75-58b59b0d833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv('preprocessed_power_consumption.csv', index_col='Timestamp')\n",
    "\n",
    "# Select relevant features for classification\n",
    "features = ['Voltage', 'Global_active_power', 'Global_intensity']\n",
    "X = df[features]\n",
    "\n",
    "\n",
    "\n",
    "# Apply categorization to the 'Voltage' column and create a new column 'Voltage_State'\n",
    "df['Voltage_State'] = df['Voltage'].apply(categorize_voltage)\n",
    "\n",
    "y = df['Voltage_State'].apply(lambda x: 1 if x == 'low_voltage' else 0)  # Label voltage sag (low_voltage = 1, others = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfd632-a802-4968-949e-4154323d200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **1. Random Forest Model for Voltage Sag Detection**\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)  # Train Random Forest model\n",
    "y_pred_rf = rf_model.predict(X)  # Predict using the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47995caa-4a8c-4566-8b2a-c88f41e46f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **2. Evaluate Random Forest for Voltage Sag Detection**\n",
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_rf):.4f}\")\n",
    "print(\"\\nClassification Report for Random Forest:\\n\", classification_report(y, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b98692-a241-4514-b640-f2f2f4e0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **3. Isolation Forest for Fault Detection**\n",
    "# Initialize Isolation Forest model\n",
    "model_iforest = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "model_iforest.fit(X)  # Train Isolation Forest model\n",
    "y_pred_iforest = model_iforest.predict(X)  # Predict anomalies\n",
    "y_pred_iforest = np.where(y_pred_iforest == 1, 0, 1)  # Convert 1 (normal) to 0, and -1 (anomaly) to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f526fd-d2ca-45cd-be04-b5df55a6798f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Define Autoencoder model structure\\ninput_layer = Input(shape=(X_scaled.shape[1],))\\nencoded = Dense(128, activation='relu')(input_layer)  # Encoder layer\\ndecoded = Dense(X_scaled.shape[1], activation='sigmoid')(encoded)  # Decoder layer (reconstruction)\\n\\nautoencoder = Model(input_layer, decoded)\\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')\\n\\n# Train Autoencoder model\\nautoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_scaled, X_scaled))\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **4. Autoencoder for Fault Detection**\n",
    "# Normalize the data before passing to Autoencoder\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "'''# Define Autoencoder model structure\n",
    "input_layer = Input(shape=(X_scaled.shape[1],))\n",
    "encoded = Dense(128, activation='relu')(input_layer)  # Encoder layer\n",
    "decoded = Dense(X_scaled.shape[1], activation='sigmoid')(encoded)  # Decoder layer (reconstruction)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train Autoencoder model\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_scaled, X_scaled))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4009405-2dc4-4796-a845-01af2b9a973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 19:22:02.955786: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "CODE_DIM = 2\n",
    "INPUT_SHAPE = X_scaled.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(INPUT_SHAPE,))\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "code = Dense(CODE_DIM, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(code)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(INPUT_SHAPE, activation='relu')(x)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer, name='anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d53be188-95bc-42fe-8296-6baf12d8c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"anomaly.weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model_name,\n",
    "                            monitor=\"val_loss\",\n",
    "                            mode=\"min\",\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only=True,\n",
    "                            verbose=1)\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta = 0, \n",
    "                              patience = 5, \n",
    "                              verbose = 1,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85e29b21-1f5d-408f-9b2a-a09ff426e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mae',\n",
    "                    optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27dac18a-2acd-48c7-81a2-07013b08f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m32418/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0632\n",
      "Epoch 1: val_loss improved from inf to 0.00134, saving model to anomaly.weights.h5\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 12ms/step - loss: 0.0632 - val_loss: 0.0013\n",
      "Epoch 2/25\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0017\n",
      "Epoch 2: val_loss did not improve from 0.00134\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6419s\u001b[0m 198ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 3/25\n",
      "\u001b[1m32421/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015\n",
      "Epoch 3: val_loss did not improve from 0.00134\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 4/25\n",
      "\u001b[1m32425/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014\n",
      "Epoch 4: val_loss improved from 0.00134 to 0.00115, saving model to anomaly.weights.h5\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 5/25\n",
      "\u001b[1m32423/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013\n",
      "Epoch 5: val_loss did not improve from 0.00115\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 6/25\n",
      "\u001b[1m32423/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0012\n",
      "Epoch 6: val_loss improved from 0.00115 to 0.00105, saving model to anomaly.weights.h5\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5312s\u001b[0m 164ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m32422/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012\n",
      "Epoch 7: val_loss did not improve from 0.00105\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/25\n",
      "\u001b[1m32422/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0012\n",
      "Epoch 8: val_loss did not improve from 0.00105\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 9/25\n",
      "\u001b[1m32424/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 9: val_loss improved from 0.00105 to 0.00085, saving model to anomaly.weights.h5\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 8.4655e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m32425/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 10: val_loss did not improve from 0.00085\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 9.6048e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m32424/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 11: val_loss did not improve from 0.00085\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 9.3339e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011\n",
      "Epoch 12: val_loss did not improve from 0.00085\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 9.0886e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m32421/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011\n",
      "Epoch 13: val_loss did not improve from 0.00085\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17354s\u001b[0m 535ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/25\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011\n",
      "Epoch 14: val_loss did not improve from 0.00085\n",
      "\u001b[1m32426/32426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 9.5877e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_scaled, X_scaled,\n",
    "                          epochs=25, batch_size=64,\n",
    "                          validation_data=(X_scaled, X_scaled),\n",
    "                          callbacks=callbacks, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd060495-7e4a-40d8-9353-87af07ff90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **5. Anomaly detection with Autoencoders**\n",
    "reconstructed = autoencoder.predict(X_scaled)  # Reconstructed data from Autoencoder\n",
    "reconstruction_error = np.mean(np.abs(reconstructed - X_scaled), axis=1)  # Reconstruction error\n",
    "\n",
    "# Set threshold for anomaly detection (top 5% reconstruction errors)\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "y_pred_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 for anomaly, 0 for normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4078c31-35ac-432b-8601-df1d10561d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **6. Evaluate Fault Detection Models**\n",
    "# Evaluate Isolation Forest\n",
    "print(\"\\nIsolation Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_iforest):.4f}\")\n",
    "print(\"\\nClassification Report for Isolation Forest:\\n\", classification_report(y, y_pred_iforest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd95cf7-e6e6-4096-98ed-abb02540af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Autoencoder\n",
    "print(\"\\nAutoencoder Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(\"\\nClassification Report for Autoencoder:\\n\", classification_report(y, y_pred_autoencoder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95095ebc-df94-405c-8a22-f84e5d8abfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Visualize Comparison (optional)**\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Random Forest\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(np.arange(len(y)), y_pred_rf, label='Random Forest Prediction', alpha=0.7)\n",
    "plt.title(\"Random Forest Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "# Plot Isolation Forest\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(np.arange(len(y)), y_pred_iforest, label='Isolation Forest Prediction', alpha=0.7)\n",
    "plt.title(\"Isolation Forest Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "# Plot Autoencoder\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(np.arange(len(y)), y_pred_autoencoder, label='Autoencoder Prediction', alpha=0.7)\n",
    "plt.title(\"Autoencoder Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649296d-5bc5-438f-a1ac-ec5b71c8bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's move forward with **Notebook 5: Model Evaluation**, where we will evaluate various classification models for **voltage sag detection** and **fault detection** using performance metrics such as **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "\n",
    "Here’s how we will structure **Notebook 5**:\n",
    "\n",
    "---\n",
    "\n",
    "### **Notebook 5: Model Evaluation**\n",
    "\n",
    "In this notebook, we will evaluate the performance of classification models, including **Random Forest** for **voltage sag detection**, and **Isolation Forest** and **Autoencoders** for **fault detection**. We will use performance metrics such as **accuracy**, **precision**, **recall**, and **F1 score** to assess each model.\n",
    "\n",
    "### **Steps**:\n",
    "\n",
    "1. **Evaluate Random Forest Model for Voltage Sag Detection**:\n",
    "\n",
    "   * Train a **Random Forest classifier** on the dataset to detect **voltage sag**.\n",
    "   * Evaluate the model using performance metrics.\n",
    "\n",
    "2. **Evaluate Isolation Forest and Autoencoders for Fault Detection**:\n",
    "\n",
    "   * Train and evaluate **Isolation Forest** and **Autoencoders** for detecting faults in the power grid.\n",
    "\n",
    "3. **Compare Models**:\n",
    "\n",
    "   * Compare the **Random Forest**, **Isolation Forest**, and **Autoencoders** using performance metrics: **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Markdown Cell for Notebook 5**:\n",
    "\n",
    "```markdown\n",
    "# Model Evaluation\n",
    "\n",
    "This notebook evaluates the classification models used for **voltage sag detection** and **fault detection**. We will use various performance metrics to evaluate the models and compare their effectiveness in detecting grid issues.\n",
    "\n",
    "### Steps:\n",
    "1. **Evaluate Random Forest model** for **voltage sag detection**.\n",
    "2. **Evaluate Isolation Forest and Autoencoders** for **fault detection**.\n",
    "3. **Compare accuracy**, **precision**, **recall**, and **F1 score** for each model.\n",
    "\n",
    "The objective is to understand how well the models perform and identify which model is most effective for detecting voltage sags and faults in the grid.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Cell for Model Evaluation**:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv('preprocessed_power_consumption.csv', index_col='Timestamp')\n",
    "\n",
    "# Select relevant features for classification\n",
    "features = ['Voltage', 'Global_active_power', 'Global_intensity']\n",
    "X = df[features]\n",
    "y = df['Voltage_State'].apply(lambda x: 1 if x == 'low_voltage' else 0)  # Label voltage sag (low_voltage = 1, others = 0)\n",
    "\n",
    "# **1. Random Forest Model for Voltage Sag Detection**\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y)  # Train Random Forest model\n",
    "y_pred_rf = rf_model.predict(X)  # Predict using the trained model\n",
    "\n",
    "# **2. Evaluate Random Forest for Voltage Sag Detection**\n",
    "print(\"\\nRandom Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_rf):.4f}\")\n",
    "print(\"\\nClassification Report for Random Forest:\\n\", classification_report(y, y_pred_rf))\n",
    "\n",
    "# **3. Isolation Forest for Fault Detection**\n",
    "# Initialize Isolation Forest model\n",
    "model_iforest = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "model_iforest.fit(X)  # Train Isolation Forest model\n",
    "y_pred_iforest = model_iforest.predict(X)  # Predict anomalies\n",
    "y_pred_iforest = np.where(y_pred_iforest == 1, 0, 1)  # Convert 1 (normal) to 0, and -1 (anomaly) to 1\n",
    "\n",
    "# **4. Autoencoder for Fault Detection**\n",
    "# Normalize the data before passing to Autoencoder\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define Autoencoder model structure\n",
    "input_layer = Input(shape=(X_scaled.shape[1],))\n",
    "encoded = Dense(128, activation='relu')(input_layer)  # Encoder layer\n",
    "decoded = Dense(X_scaled.shape[1], activation='sigmoid')(encoded)  # Decoder layer (reconstruction)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train Autoencoder model\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_scaled, X_scaled))\n",
    "\n",
    "# **5. Anomaly detection with Autoencoders**\n",
    "reconstructed = autoencoder.predict(X_scaled)  # Reconstructed data from Autoencoder\n",
    "reconstruction_error = np.mean(np.abs(reconstructed - X_scaled), axis=1)  # Reconstruction error\n",
    "\n",
    "# Set threshold for anomaly detection (top 5% reconstruction errors)\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "y_pred_autoencoder = (reconstruction_error > threshold).astype(int)  # 1 for anomaly, 0 for normal\n",
    "\n",
    "# **6. Evaluate Fault Detection Models**\n",
    "# Evaluate Isolation Forest\n",
    "print(\"\\nIsolation Forest Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_iforest):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_iforest):.4f}\")\n",
    "print(\"\\nClassification Report for Isolation Forest:\\n\", classification_report(y, y_pred_iforest))\n",
    "\n",
    "# Evaluate Autoencoder\n",
    "print(\"\\nAutoencoder Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Precision: {precision_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"Recall: {recall_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y, y_pred_autoencoder):.4f}\")\n",
    "print(\"\\nClassification Report for Autoencoder:\\n\", classification_report(y, y_pred_autoencoder))\n",
    "\n",
    "# **Visualize Comparison (optional)**\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Random Forest\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(np.arange(len(y)), y_pred_rf, label='Random Forest Prediction', alpha=0.7)\n",
    "plt.title(\"Random Forest Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "# Plot Isolation Forest\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(np.arange(len(y)), y_pred_iforest, label='Isolation Forest Prediction', alpha=0.7)\n",
    "plt.title(\"Isolation Forest Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "# Plot Autoencoder\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(np.arange(len(y)), y_pred_autoencoder, label='Autoencoder Prediction', alpha=0.7)\n",
    "plt.title(\"Autoencoder Predictions\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Prediction (0: Normal, 1: Anomaly)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of the Notebook**:\n",
    "\n",
    "1. **Random Forest for Voltage Sag Detection**:\n",
    "\n",
    "   * We train a **Random Forest** classifier to detect **voltage sag** (e.g., `low_voltage` condition) and evaluate it using performance metrics like **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "\n",
    "2. **Isolation Forest for Fault Detection**:\n",
    "\n",
    "   * **Isolation Forest** is used for **fault detection**, identifying anomalies in the grid data. We evaluate the model using **classification metrics**.\n",
    "\n",
    "3. **Autoencoder for Fault Detection**:\n",
    "\n",
    "   * **Autoencoders** are used to detect **faults** based on **reconstruction error**. The model is trained to reconstruct the input data, and large reconstruction errors indicate anomalies.\n",
    "\n",
    "4. **Evaluation**:\n",
    "\n",
    "   * The performance of each model (Random Forest, Isolation Forest, Autoencoder) is evaluated using **accuracy**, **precision**, **recall**, and **F1 score**.\n",
    "\n",
    "5. **Visualization**:\n",
    "\n",
    "   * The predictions from **Random Forest**, **Isolation Forest**, and **Autoencoders** are visualized for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**:\n",
    "\n",
    "1. **Run the notebook** to evaluate the performance of the **Random Forest**, **Isolation Forest**, and **Autoencoders** models.\n",
    "2. **Analyze the evaluation results** and see which model performs best for **voltage sag detection** and **fault detection**.\n",
    "3. **Compare the models** based on the **performance metrics** and choose the best one for deployment.\n",
    "\n",
    "Let me know if you'd like help with any part of this notebook, or if you'd like to continue running it for model evaluation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb75f1-b075-4665-8296-513eccf722a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
