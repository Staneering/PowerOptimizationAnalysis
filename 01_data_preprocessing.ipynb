{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8891781f",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "    ## Data Preprocessing\n",
    "    This notebook handles the data loading, cleaning, and preprocessing for the power consumption dataset.\n",
    "    \n",
    "    Steps:\n",
    "    1. Load the dataset\n",
    "    2. Handle missing values\n",
    "    3. Normalize continuous features (e.g., Global_active_power, Voltage)\n",
    "    4. Combine Date and Time into a Timestamp column\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369b4f8b-7d9b-4578-a97b-8e899e10ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m238.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m506.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /root/myenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.5 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Requirement already satisfied: numpy in /root/myenv/lib/python3.12/site-packages (2.2.5)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /root/myenv/lib/python3.12/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m198.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.0 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29a23d3-57c5-4a86-be21-8079dac01bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Ibrah\\\\Downloads\\\\individual+household+electric+power+consumption.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m zip_file_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mIbrah\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mindividual+household+electric+power+consumption.zip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m extract_dir = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mIbrah\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mpower_consumption_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[32m     16\u001b[39m     zip_ref.extractall(extract_dir)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Step 2: Load the CSV file from the extracted folder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1331\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1333\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Ibrah\\\\Downloads\\\\individual+household+electric+power+consumption.zip'"
     ]
    }
   ],
   "source": [
    "\n",
    "#### **Code Cell**:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "# Step 1: Extract the ZIP file\n",
    "zip_file_path = r\"C:\\Users\\Ibrah\\Downloads\\individual+household+electric+power+consumption.zip\"\n",
    "extract_dir = r\"C:\\\\Users\\\\Ibrah\\\\Downloads\\\\power_consumption_data\\\\\"\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "# Step 2: Load the CSV file from the extracted folder\n",
    "csv_file_path = os.path.join(extract_dir, 'household_power_consumption.txt')\n",
    "df = pd.read_csv(csv_file_path, sep=';', header=0, low_memory=False, na_values=[\"?\"])\n",
    "\n",
    "# Step 1: Combine Date and Time into a Timestamp column\n",
    "df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Step 2: Drop original Date and Time columns\n",
    "df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "# Step 3: Handle missing values\n",
    "# Fill missing values with the mean of the respective column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Step 4: Normalize the continuous features using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "continuous_columns = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "                      'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "df[continuous_columns] = scaler.fit_transform(df[continuous_columns])\n",
    "\n",
    "# Check the first few rows of the cleaned dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9d691-2a34-4cfb-9b11-1a0859219954",
   "metadata": {},
   "source": [
    "\n",
    "#### **Markdown Cell**:\n",
    "\n",
    "\n",
    "### Data Summary\n",
    "\n",
    "In this section, we check for missing values and display basic summary statistics.\n",
    "\n",
    "We will:\n",
    "- Check for missing values in the dataset.\n",
    "- Provide summary statistics of the continuous features to understand their distributions.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f15a467-082e-4c96-825a-9914484faad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Global_active_power      0\n",
      "Global_reactive_power    0\n",
      "Voltage                  0\n",
      "Global_intensity         0\n",
      "Sub_metering_1           0\n",
      "Sub_metering_2           0\n",
      "Sub_metering_3           0\n",
      "dtype: int64\n",
      "\n",
      "Summary Stats:\n",
      "        Global_active_power  Global_reactive_power       Voltage  \\\n",
      "count         2.075259e+06           2.075259e+06  2.075259e+06   \n",
      "mean          9.194415e-02           8.900322e-02  5.699469e-01   \n",
      "std           9.511638e-02           8.058576e-02  1.040272e-01   \n",
      "min           0.000000e+00           0.000000e+00  0.000000e+00   \n",
      "25%           2.118414e-02           3.453237e-02  5.111470e-01   \n",
      "50%           5.015390e-02           7.338129e-02  5.738288e-01   \n",
      "75%           1.307261e-01           1.381295e-01  6.352181e-01   \n",
      "max           1.000000e+00           1.000000e+00  1.000000e+00   \n",
      "\n",
      "       Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "count      2.075259e+06    2.075259e+06    2.075259e+06    2.075259e+06  \n",
      "mean       9.186223e-02    1.274913e-02    1.623150e-02    2.083370e-01  \n",
      "std        9.162843e-02    6.948178e-02    7.231838e-02    2.704573e-01  \n",
      "min        0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00  \n",
      "25%        2.489627e-02    0.000000e+00    0.000000e+00    0.000000e+00  \n",
      "50%        5.394191e-02    0.000000e+00    0.000000e+00    3.225806e-02  \n",
      "75%        1.286307e-01    0.000000e+00    1.250000e-02    5.483871e-01  \n",
      "max        1.000000e+00    1.000000e+00    1.000000e+00    1.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### **Code Cell**:\n",
    "\n",
    "# Step 5: Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Basic statistics\n",
    "stats = df.describe()\n",
    "\n",
    "# Display missing values and basic stats\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "print(\"\\nSummary Stats:\\n\", stats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19a46b-7894-46db-a83f-10a5f35f9af2",
   "metadata": {},
   "source": [
    "### **Explanation of the Code**:\n",
    "\n",
    "1. **Data Loading**: The dataset is loaded from a CSV file with `pd.read_csv()`. We specify `na_values=[\"?\"]` to treat `?` as missing values.\n",
    "2. **Timestamp Creation**: We combine the `Date` and `Time` columns into a `Timestamp` column and set it as the index of the DataFrame.\n",
    "3. **Handling Missing Values**: Missing values are filled with the **mean** of each column using `fillna()`.\n",
    "4. **Normalization**: We use **Min-Max Scaling** to normalize the continuous features (e.g., **Global\\_active\\_power**, **Voltage**, etc.) to the range \\[0, 1].\n",
    "5. **Missing Values Check & Summary Stats**: We display any missing values and summarize the dataset’s basic statistics (mean, min, max, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c540936-b324-4a85-a9a7-c9e1b2f1a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "df.to_csv('preprocessed_power_consumption.csv')  # or use df.to_pickle('preprocessed_power_consumption.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b489c0-d9b6-4324-b79b-a1e4efc77eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
